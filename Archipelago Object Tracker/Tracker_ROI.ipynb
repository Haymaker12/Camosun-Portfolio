{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"OAw01vTVEufK"},"outputs":[],"source":["import itertools\n","import dlib\n","import enum\n","import numpy as np\n","import time\n","import cv2\n","import imutils\n","from imutils.video import FPS\n","import pandas as pd\n","from scipy.spatial import distance as dist\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wRowMLtNBlts"},"outputs":[],"source":["class Direction(enum.Enum):\n","  ONBOARD = 1\n","  OFFBOARD= -1\n","  NAN = 0"]},{"cell_type":"markdown","metadata":{"id":"o-VUPCSTrTnv"},"source":["### Centroid Tracker class"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4HIjnuXrrR1u"},"outputs":[],"source":["class CentroidTracker:\n","\tdef __init__(self, maxDisappeared=50, maxDistance=50):\n","\t\t# initialize the next unique object ID along with two ordered\n","\t\t# dictionaries used to keep track of mapping a given object\n","\t\t# ID to its centroid and number of consecutive frames it has\n","\t\t# been marked as \"disappeared\", respectively\n","\t\tself.nextObjectID = 0\n","\t\tself.objects = OrderedDict()\n","\t\tself.disappeared = OrderedDict()\n","\n","\t\t# store the number of maximum consecutive frames a given\n","\t\t# object is allowed to be marked as \"disappeared\" until we\n","\t\t# need to deregister the object from tracking\n","\t\tself.maxDisappeared = maxDisappeared\n","\n","\t\t# store the maximum distance between centroids to associate\n","\t\t# an object -- if the distance is larger than this maximum\n","\t\t# distance we'll start to mark the object as \"disappeared\"\n","\t\tself.maxDistance = maxDistance\n","\n","\tdef register(self, centroid):\n","\t\t# when registering an object we use the next available object\n","\t\t# ID to store the centroid\n","\t\tself.objects[self.nextObjectID] = centroid\n","\t\tself.disappeared[self.nextObjectID] = 0\n","\t\tself.nextObjectID += 1\n","\n","\tdef deregister(self, objectID):\n","\t\t# to deregister an object ID we delete the object ID from\n","\t\t# both of our respective dictionaries\n","\t\tprint(\"deregistered {}-Object\".format(objectID))\n","\t\tto = trackableObjects.get(objectID, None)\n","\t\tto.end_of_tracking()\n","\t\tdel self.objects[objectID]\n","\t\tdel self.disappeared[objectID]\n","\n","\tdef update(self, rects):\n","\t\t# check to see if the list of input bounding box rectangles\n","\t\t# is empty\n","\t\tif len(rects) == 0:\n","\t\t\t# loop over any existing tracked objects and mark them\n","\t\t\t# as disappeared\n","\t\t\tfor objectID in list(self.disappeared.keys()):\n","\t\t\t\tself.disappeared[objectID] += 1\n","\n","\t\t\t\t# if we have reached a maximum number of consecutive\n","\t\t\t\t# frames where a given object has been marked as\n","\t\t\t\t# missing, deregister it\n","\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n","\t\t\t\t\tself.deregister(objectID)\n","\n","\t\t\t# return early as there are no centroids or tracking info\n","\t\t\t# to update\n","\t\t\treturn self.objects\n","\n","\t\t# initialize an array of input centroids for the current frame\n","\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n","\n","\t\t# loop over the bounding box rectangles\n","\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n","\t\t\t# use the bounding box coordinates to derive the centroid\n","\t\t\tcX = int((startX + endX) / 2.0)\n","\t\t\tcY = int((startY + endY) / 2.0)\n","\t\t\tinputCentroids[i] = (cX, cY)\n","\n","\t\t# if we are currently not tracking any objects take the input\n","\t\t# centroids and register each of them\n","\t\tif len(self.objects) == 0:\n","\t\t\tfor i in range(0, len(inputCentroids)):\n","\t\t\t\tself.register(inputCentroids[i])\n","\n","\t\t# otherwise, are are currently tracking objects so we need to\n","\t\t# try to match the input centroids to existing object\n","\t\t# centroids\n","\t\telse:\n","\t\t\t# grab the set of object IDs and corresponding centroids\n","\t\t\tobjectIDs = list(self.objects.keys())\n","\t\t\tobjectCentroids = list(self.objects.values())\n","\n","\t\t\t# compute the distance between each pair of object\n","\t\t\t# centroids and input centroids, respectively -- our\n","\t\t\t# goal will be to match an input centroid to an existing\n","\t\t\t# object centroid\n","\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n","\n","\t\t\t# in order to perform this matching we must (1) find the\n","\t\t\t# smallest value in each row and then (2) sort the row\n","\t\t\t# indexes based on their minimum values so that the row\n","\t\t\t# with the smallest value as at the *front* of the index\n","\t\t\t# list\n","\t\t\trows = D.min(axis=1).argsort()\n","\n","\t\t\t# next, we perform a similar process on the columns by\n","\t\t\t# finding the smallest value in each column and then\n","\t\t\t# sorting using the previously computed row index list\n","\t\t\tcols = D.argmin(axis=1)[rows]\n","\n","\t\t\t# in order to determine if we need to update, register,\n","\t\t\t# or deregister an object we need to keep track of which\n","\t\t\t# of the rows and column indexes we have already examined\n","\t\t\tusedRows = set()\n","\t\t\tusedCols = set()\n","\n","\t\t\t# loop over the combination of the (row, column) index\n","\t\t\t# tuples\n","\t\t\tfor (row, col) in zip(rows, cols):\n","\t\t\t\t# if we have already examined either the row or\n","\t\t\t\t# column value before, ignore it\n","\t\t\t\tif row in usedRows or col in usedCols:\n","\t\t\t\t\tcontinue\n","\n","\t\t\t\t# if the distance between centroids is greater than\n","\t\t\t\t# the maximum distance, do not associate the two\n","\t\t\t\t# centroids to the same object\n","\t\t\t\tif D[row, col] > self.maxDistance:\n","\t\t\t\t\tcontinue\n","\n","\t\t\t\t# otherwise, grab the object ID for the current row,\n","\t\t\t\t# set its new centroid, and reset the disappeared\n","\t\t\t\t# counter\n","\t\t\t\tobjectID = objectIDs[row]\n","\t\t\t\tself.objects[objectID] = inputCentroids[col]\n","\t\t\t\tself.disappeared[objectID] = 0\n","\n","\t\t\t\t# indicate that we have examined each of the row and\n","\t\t\t\t# column indexes, respectively\n","\t\t\t\tusedRows.add(row)\n","\t\t\t\tusedCols.add(col)\n","\n","\t\t\t# compute both the row and column index we have NOT yet\n","\t\t\t# examined\n","\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n","\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n","\n","\t\t\t# in the event that the number of object centroids is\n","\t\t\t# equal or greater than the number of input centroids\n","\t\t\t# we need to check and see if some of these objects have\n","\t\t\t# potentially disappeared\n","\t\t\tif D.shape[0] >= D.shape[1]:\n","\t\t\t\t# loop over the unused row indexes\n","\t\t\t\tfor row in unusedRows:\n","\t\t\t\t\t# grab the object ID for the corresponding row\n","\t\t\t\t\t# index and increment the disappeared counter\n","\t\t\t\t\tobjectID = objectIDs[row]\n","\t\t\t\t\tself.disappeared[objectID] += 1\n","\n","\t\t\t\t\t# check to see if the number of consecutive\n","\t\t\t\t\t# frames the object has been marked \"disappeared\"\n","\t\t\t\t\t# for warrants deregistering the object\n","\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n","\t\t\t\t\t\tself.deregister(objectID)\n","\n","\t\t\t# otherwise, if the number of input centroids is greater\n","\t\t\t# than the number of existing object centroids we need to\n","\t\t\t# register each new input centroid as a trackable object\n","\t\t\telse:\n","\t\t\t\tfor col in unusedCols:\n","\t\t\t\t\tself.register(inputCentroids[col])\n","\n","\t\t# return the set of trackable objects\n","\t\treturn self.objects"]},{"cell_type":"markdown","metadata":{"id":"DrFVJg9hrpFU"},"source":["### Tracked object data class, makes for unique tracking"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9m9sdCWrroTX"},"outputs":[],"source":["class TrackableObject:\n","\tdef __init__(self, objectID, centroid, first_frame, label, direction, fisheries_data):\n","\t\t# store the object ID, then initialize a list of centroids\n","\t\t# using the current centroid\n","\t\tself.objectID = objectID\n","\t\tself.centroids = [centroid]\n","\t\tself.first_frame = first_frame\n","\t\tself.label = label\n","\t\tself.direction = direction\n","\n","\t\tself.fishery_export = fisheries_data\n","\n","\t\t# initialize a boolean used to indicate if the object has\n","\t\t# already been counted or not\n","\t\tself.counted = False\n","\n","\tdef end_of_tracking(self):\n","\t  # Add data from tracking to export\n","\t\tself.fishery_export.addData(self.label,\n","\t\t                            self.first_frame, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.last_frame, \n","\t\t                       \t\t\t\"Onboard\" if self.direction == Direction.ONBOARD \n","\t\t\t\t\t\t\t\t\t\t\t\t\t        else \"Offboard\")"]},{"cell_type":"markdown","metadata":{"id":"31UGv7mSBltv"},"source":["### John's data export class FisheriesData"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QX9WNK_eBltv"},"outputs":[],"source":["import pandas as pd\n","\n","class FisheriesData:\n","    def __init__(self):\n","        self.species = \"species\"\n","        self.timeStampStart = \"time_stamp_start\"\n","        self.timeStampEnd = \"time_stamp_end\"\n","        self.direction = \"direction\"\n","        self.dataFrame = []\n","        self.speciesList = []\n","        self.timeStampStartList = []\n","        self.timeStampEndList = []\n","        self.directionList = []\n","    \n","    def makeDF(self):\n","        self.dataFrame = pd.DataFrame({self.species:self.speciesList,self.timeStampStart:self.timeStampStartList,self.timeStampEnd:self.timeStampEndList,self.direction:self.directionList})\n","    \n","    def addData(self, species, timeStampStart, timeStampEnd, direction):\n","        self.speciesList.append(species)\n","        self.timeStampStartList.append(timeStampStart)\n","        self.timeStampEndList.append(timeStampEnd)\n","        self.directionList.append(direction)\n","\n","    def addDictData(self, dictionary):\n","        for k, v in dictionary.items():\n","            for kk, vv in v.items():\n","                if type(kk) is tuple:\n","                    x, y = kk\n","                    self.timeStampStartList.append(x)\n","                    self.timeStampEndList.append(y)\n","                    self.speciesList.append(vv)\n","                else:\n","                    self.directionList.append(vv)\n","\n","    def writeCSV(self, fileName):\n","        file_name = fileName + '.csv'\n","        self.dataFrame.to_csv(file_name, sep='\\t', encoding='utf-8')\n","\n","    def writeExcel(self, fileName):\n","        file_name = fileName + '.xlsx'\n","        self.dataFrame.to_excel(file_name, sheet_name='sheet1', index=False)\n","\n","    def writeXML(self, fileName):\n","        file_name = fileName + '.xml'\n","        self.dataFrame.to_xml(file_name)\n","\n","    def writeJSON(self, fileName):\n","        file_name = fileName + '.json'\n","        self.dataFrame.to_json(file_name, orient='records', indent=2)"]},{"cell_type":"markdown","metadata":{"id":"xyNrlExbBltw"},"source":["### Bounding Box Class (tracker alt)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TC-ouJ3ABltw"},"outputs":[],"source":["class BBox:\n","  x1 = 0\n","  y1 = 0\n","  x2 = 0\n","  y2 = 0\n","  label = \"\"\n","  \n","  # Consturctor for BBox taking x1,x2,y1,y2\n","  # def __init__(self, x1, x2, y1, y2, label):\n","  #   if x1>x2 or y1>y2:\n","  #     raise ValueError(\"Coordinates are invalid\")\n","  #   if label == \"\" or not label:\n","  #     raise ValueError(\"Please include label\")\n","  #   self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n","  #   self.label = label\n","\n","  # Constructor for BBox taking x,y w,h\n","  # Use for Yolo detections\n","  def __init__(self, x:int, y:int, w:int, h:int, label:str):\n","    if x>(x+w) or y>(y+h):\n","      raise ValueError(\"Coordinates are invalid\")\n","    if label == \"\" or not label:\n","      raise ValueError(\"Please include label\")\n","    self.x1, self.y1, self.x2, self.y2 = x, y, (x+w), (y+h)\n","    self.label = label\n","\n","  # Takes a BBox class instance to compare the overlap area \n","  # and returns an value for overlap area\n","  def intersection_area(self, bbox: object) -> float:\n","    if type(bbox) != self:\n","      raise TypeError(\"BBox should be an instance of a BBox Class\")\n","    dx = min(self.x1, bbox.x1) - max(self.x2, bbox.x2)\n","    dy = min(self.y1, bbox.y1) - max(self.y2, bbox.y2)\n","    if (dx>=0) and (dy>=0):\n","      if self.label == bbox.label:\n","        return dx*dy\n","    return -1\n","\n","  # Takes a BBox and compares x positions \n","  def direction_of_motion(self, bbox: object):\n","    if type(bbox) != self:\n","      raise TypeError(\"BBox should be an instance of a BBox Class\")\n","    dx = self.x1 - bbox.x1\n","    if dx > 0:\n","      return Direction.ONBOARD\n","    elif dx < 0:\n","      return Direction.OFFBOARD\n","    elif dx == 0:\n","      return Direction.NAN"]},{"cell_type":"markdown","metadata":{},"source":["### Black and white the frame"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def get_binary_frame(frame, frame2):\n","  # Convert frame to RGB frame\n","  rgb_frame = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2RGB)\n","  rgb_frame2 = cv2.cvtColor(src=frame2, code=cv2.COLOR_BGR2RGB)\n","\n","  # Convert the image to grayscale format\n","  gray_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n","  gray_frame2 = cv2.cvtColor(rgb_frame2, cv2.COLOR_BGR2GRAY)\n","\n","  # Blur the image for smoothing\n","  prepared_frame = cv2.GaussianBlur(src=gray_frame, ksize=(5, 5), sigmaX=0)\n","  previous_frame = cv2.GaussianBlur(src=gray_frame2, ksize=(5, 5), sigmaX=0)\n","\n","  # Calculate difference and update previous frame\n","  diff_frame = cv2.absdiff(src1=previous_frame, src2=prepared_frame)\n","\n","  # Dilute the image a bit to make differences more seeable; more suitable for contour detection\n","  kernel = np.ones((5, 5))\n","  diff_frame = cv2.dilate(diff_frame, kernel, 1)\n","\n","  # Only take different areas that are different enough (>20 / 255)\n","  thresh_frame = cv2.threshold(src=diff_frame, thresh=99, maxval=250, type=cv2.THRESH_BINARY)[1]\n","  return thresh_frame"]},{"cell_type":"markdown","metadata":{"id":"fv2jIifXBltx"},"source":["# Yolo Detector modified from object_detector.ipynb"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# INPUT_FILE='penguin.mp4'"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["INPUT_FILE='Fish_Training_3.mp4'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# INPUT_FILE='crab.mp4'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4_Hq-qJ-Bltx"},"outputs":[{"name":"stdout","output_type":"stream","text":["created new trackable object: temp_label\n","created new trackable object: temp_label\n","created new trackable object: temp_label\n","created new trackable object: temp_label\n","deregistered 0-Object\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'end_of_tracking'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mh:\\Programing\\Archipelago\\Archipelago-Object-Tracking\\Tracker_ROI.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=83'>84</a>\u001b[0m \ttrackableObjects \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=85'>86</a>\u001b[0m \u001b[39m# Update the centroid tracker to associate the old object centroid\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=86'>87</a>\u001b[0m \u001b[39m# with the newly computed centroid\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=87'>88</a>\u001b[0m objects \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39;49mupdate(rects)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=88'>89</a>\u001b[0m \u001b[39m# print(objects)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=89'>90</a>\u001b[0m \u001b[39m# loop over the tracked objects\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=90'>91</a>\u001b[0m \u001b[39mfor\u001b[39;00m (objectID, centroid) \u001b[39min\u001b[39;00m objects\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=91'>92</a>\u001b[0m \t\u001b[39m# check to see if a trackable object exists for the current\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=92'>93</a>\u001b[0m \t\u001b[39m# object ID\u001b[39;00m\n","\u001b[1;32mh:\\Programing\\Archipelago\\Archipelago-Object-Tracking\\Tracker_ROI.ipynb Cell 17\u001b[0m in \u001b[0;36mCentroidTracker.update\u001b[1;34m(self, rects)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=45'>46</a>\u001b[0m \t\u001b[39m# if we have reached a maximum number of consecutive\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=46'>47</a>\u001b[0m \t\u001b[39m# frames where a given object has been marked as\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=47'>48</a>\u001b[0m \t\u001b[39m# missing, deregister it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=48'>49</a>\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisappeared[objectID] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxDisappeared:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=49'>50</a>\u001b[0m \t\t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mderegister(objectID)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=51'>52</a>\u001b[0m \u001b[39m# return early as there are no centroids or tracking info\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=52'>53</a>\u001b[0m \u001b[39m# to update\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=53'>54</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjects\n","\u001b[1;32mh:\\Programing\\Archipelago\\Archipelago-Object-Tracking\\Tracker_ROI.ipynb Cell 17\u001b[0m in \u001b[0;36mCentroidTracker.deregister\u001b[1;34m(self, objectID)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mderegistered \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m-Object\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(objectID))\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=31'>32</a>\u001b[0m to \u001b[39m=\u001b[39m trackableObjects\u001b[39m.\u001b[39mget(objectID, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=32'>33</a>\u001b[0m to\u001b[39m.\u001b[39;49mend_of_tracking()\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=33'>34</a>\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjects[objectID]\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Programing/Archipelago/Archipelago-Object-Tracking/Tracker_ROI.ipynb#ch0000018?line=34'>35</a>\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisappeared[objectID]\n","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'end_of_tracking'"]}],"source":["OUTPUT_FILE='output2.mp4'\n","\n","H=None\n","W=None\n","\n","# capture input video\n","video_capture = cv2.VideoCapture(INPUT_FILE)\n","\n","# get input video's frame size\n","frame_width = int(video_capture.get(3))\n","frame_height = int(video_capture.get(4))\n","frame_size = (frame_width,frame_height)\n","\n","# get input video's fps\n","input_fps = video_capture.get(cv2.CAP_PROP_FPS)\n","\n","fps = FPS().start()\n","\n","# fourcc = cv2.VideoWriter_fourcc(*\"MJPG\") # for avi\n","fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") # for mp4\n","writer = cv2.VideoWriter(OUTPUT_FILE, fourcc, input_fps, frame_size, True)\n","\n","cnt = 0\n","\n","trackers = []\n","ct = CentroidTracker(maxDisappeared=10, maxDistance=55)\n","trackableObjects = {}\n","\n","# initialize FisheriesData to use for aggregating export data\n","fishery_export = FisheriesData()\n","last_frame = None\n","# iterate through video frames\n","while True:\n","\trects = []\n","\tcnt+=1\n","\n","\t# print (\"Frame number\", cnt)\n","\tok, image = video_capture.read()\n","\tif last_frame is None:\n","\t\tlast_frame = image\n","\t\t\n","\t# blob = get_binary_frame(image, last_frame)\n","\t# blob = cv2.dnn.blobFromImage(image, 1)\n","\tfor tracker in trackers:\n","\t\t# update the tracker and grab the updated position\n","\t\ttracker.update(image)\n","\t\tpos = tracker.get_position()\n","\n","\t\t# unpack the position object\n","\t\tstartX = int(pos.left())\n","\t\tstartY = int(pos.top())\n","\t\tendX = int(pos.right())\n","\t\tendY = int(pos.bottom())\n","\n","\t\t# add the bounding box coordinates to the rectangles list\n","\t\trects.append((startX, startY, endX, endY))\n","\n","\tkey = cv2.waitKey(0) & 0xFF\n","\n","\tif key == ord(\"q\"):\n","\t\tbreak\n","\telif key == ord(\"a\"):\n","\t\tbox = cv2.selectROI(image)\n","\t\t(x, y, width, height) = box\n","\t\t# construct a dlib rectangle object from the bounding\n","\t\t# box coordinates and then start the dlib correlation\n","\t\t# tracker\n","\t\ttracker = dlib.correlation_tracker()\n","\t\trect = dlib.rectangle(x, y, x+width, y+height)\n","\t\ttracker.start_track(image, rect)\n","\n","\t\t# add the tracker to our list of trackers so we can\n","\t\t# utilize it during skip frames\n","\t\ttrackers.append(tracker)\n","\n","\t\t# update our list of bounding box coordinates, confidences,\n","\t\t# and class IDs\n","\t\t# boxes.append([x, y, int(width), int(height)])\n","\telif key == ord(\"f\"):\n","\t\trects = []\n","\telif key == ord(\"r\"):\n","\t\trects = []\n","\t\ttrackers = []\n","\t\ttrackableObjects = {}\n","\n","\t# Update the centroid tracker to associate the old object centroid\n","\t# with the newly computed centroid\n","\tobjects = ct.update(rects)\n","\t# print(objects)\n","\t# loop over the tracked objects\n","\tfor (objectID, centroid) in objects.items():\n","\t\t# check to see if a trackable object exists for the current\n","\t\t# object ID\n","\t\tto = trackableObjects.get(objectID, None)\n","\n","\t\t# if there is no existing trackable object, create one\n","\t\tif to is None:\n","\t\t\t#objectID, centroid, first_frame, label, direction, fisheries_data\n","\t\t\tto = TrackableObject(objectID=objectID, centroid=centroid, first_frame=cnt, \n","\t\t\t                     label=\"Object-{}\".format(objectID), direction=Direction.ONBOARD, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t fisheries_data=fishery_export)\n","\t\t\tprint(\"created new trackable object: {}\".format(\"temp_label\"))\n","\t\t# otherwise, there is a trackable object so we can utilize it\n","\t\t# to determine direction\n","\t\telse:\n","\t\t\t# the difference between the y-coordinate of the *current*\n","\t\t\t# centroid and the mean of *previous* centroids will tell\n","\t\t\t# us in which direction the object is moving (negative for\n","\t\t\t# 'up' and positive for 'down')\n","\t\t\ty = [c[1] for c in to.centroids]\n","\t\t\tdirection = centroid[1] - np.mean(y)\n","\t\t\tto.centroids.append(centroid)\n","\n","\t\t\t# check to see if the object has been counted or not\n","\t\t\tif not to.counted:\n","\t\t\t\t# if the direction is negative (indicating the object\n","\t\t\t\t# is moving up)\n","\t\t\t\tif direction < 0 :\n","\t\t\t\t\tto.direction = Direction.ONBOARD\n","\t\t\t\t\tto.counted = True\n","\t\t\t\t# if the direction is positive (indicating the object\n","\t\t\t\t# is moving down)\n","\t\t\t\telif direction > 0:\n","\t\t\t\t\tto.direction = Direction.OFFBOARD\n","\t\t\t\t\tto.counted = True\n","\t\t\n","\t\t# print(\"{}-{}\".format(to.objectID, to.label))\n","\t\tto.last_frame = cnt\n","\t\t# store the trackable object in our dictionary\n","\t\ttrackableObjects[objectID] = to\n","\t\t# Display the Centroid in the frame\n","\t\ttext = \"ID {}\".format(objectID)\n","\t\tcv2.putText(image, text, (centroid[0] - 10, centroid[1] - 10),\n","\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (1, 1, 1), 2)\n","\t\tcv2.circle(image, (centroid[0], centroid[1]), 4, (255, 255, 255), -1)\n","\n","\t# show the output image\n","\tcv2.imshow(\"output\", image)\n","\t# cv2.imshow(\"Blob output\", blob)\n","\t# Convert image colors back to bgr from rgb for presentation\n","\t# image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\twriter.write(cv2.resize(image,frame_size))\n","\tfps.update()\n","\t\n","\tlast_frame = image\n","\tif ok is None:\n","\t\tbreak\n","\n","fps.stop()\n","\n","print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n","print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n","\n","# Export FisheriesData\n","fishery_export.makeDF()\n","fishery_export.writeCSV('Testing')\n","fishery_export.writeJSON('Testing')\n","# fishery_export.writeXML('Testing')\n","\n","# do a bit of cleanup\n","cv2.destroyAllWindows()\n","\n","# release the file pointers\n","print(\"[INFO] cleaning up...\")\n","writer.release()\n","video_capture.release()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMn/p7+gGbfFj5spcy0W7UY","collapsed_sections":["t0uWq6cerz2m","o-VUPCSTrTnv","DrFVJg9hrpFU","31UGv7mSBltv","xyNrlExbBltw"],"name":"Tracker_ROI.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('OpenCV')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"dfd8b5841c8fdbae2936e39ec67041aa4f03e46e0e941bdc94af56c5f1f7a941"}}},"nbformat":4,"nbformat_minor":0}
