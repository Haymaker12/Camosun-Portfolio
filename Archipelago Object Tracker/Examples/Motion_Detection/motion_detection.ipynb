{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Motion with OpenCV\n",
    "---\n",
    "This motion detecting model can be divided into 3 parts.\n",
    "1. Compare previous frame and current frame to get differences on the frame.\n",
    "2. Find out contours from the frame that has differences.\n",
    "3. Draw bounding box around each contour on the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a video capture object\n",
    "video = cv2.VideoCapture(\"people.mp4\")\n",
    "\n",
    "# Check that video is opened\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "# Read video with read() method\n",
    "ok, frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video file\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect object's motion from the video and draw bounding box around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define previous_frame to None\n",
    "previous_frame = None\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get frame from video\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB frame\n",
    "    rgb_frame = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2RGB)\n",
    "    # rgb_frame_2 will be used for contour window\n",
    "    rgb_frame_2 = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to grayscale format\n",
    "    gray_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Blur the image for smoothing\n",
    "    prepared_frame = cv2.GaussianBlur(src=gray_frame, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    # Set previous frame and continue if there is None\n",
    "    if (previous_frame is None):\n",
    "        # First frame; there is no previous one yet\n",
    "        previous_frame = prepared_frame\n",
    "        continue\n",
    "\n",
    "\n",
    "    ### Part 1 ###\n",
    "    # Calculate difference and update previous frame\n",
    "    diff_frame = cv2.absdiff(src1=previous_frame, src2=prepared_frame)\n",
    "    previous_frame = prepared_frame\n",
    "\n",
    "    # Dilute the image a bit to make differences more seeable; more suitable for contour detection\n",
    "    kernel = np.ones((5, 5))\n",
    "    diff_frame = cv2.dilate(diff_frame, kernel, 1)\n",
    "\n",
    "    # Only take different areas that are different enough (>20 / 255)\n",
    "    thresh_frame = cv2.threshold(src=diff_frame, thresh=20, maxval=255, type=cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Display thresh_frame on the window\n",
    "    cv2.imshow('1. Show changes on the frame', thresh_frame)\n",
    "\n",
    "\n",
    "    ### Part 2 ###\n",
    "    # Find contours from thresh_frame\n",
    "    contours, _ = cv2.findContours(image=thresh_frame, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Drawing contours on rgb_frame_2\n",
    "    cv2.drawContours(image=rgb_frame_2, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Display rgb_frame_2 on the window\n",
    "    cv2.imshow('2. Contours', rgb_frame_2)\n",
    "\n",
    "\n",
    "    ### Part 3 ###\n",
    "    # Drawing rectangles on rgb_frame\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 700:\n",
    "            # too small: skip!\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(img=rgb_frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    # Display rgb_frame on the window\n",
    "    cv2.imshow('Motion detector', rgb_frame)\n",
    "\n",
    "    if (cv2.waitKey(50) == 27):\n",
    "        # out.release()\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62def48e81a9cca8f364c24dfb725fce9c4e9f1dbd488585f19795e5af0a0958"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('object_tracking.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
