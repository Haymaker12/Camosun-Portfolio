{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DetectionOutput:\n",
    "    def __init__(self):\n",
    "        self.dataFrame = []\n",
    "        self.frame = \"frame\"\n",
    "        self.xmax = \"xmax\"\n",
    "        self.xmin = \"xmin\"\n",
    "        self.ymax = \"ymax\"\n",
    "        self.ymin = \"ymin\"\n",
    "        self.conf = \"confidence\"\n",
    "        self.classID = \"classID\"\n",
    "        self.frameList = []\n",
    "        self.xmaxList = []\n",
    "        self.xminList = []\n",
    "        self.ymaxList = []\n",
    "        self.yminList = []\n",
    "        self.confList = []\n",
    "        self.classIDList = []\n",
    "\n",
    "    def addData(self, frame, xmax, xmin, ymax, ymin, confidence, classID):\n",
    "        self.frameList.append(frame)\n",
    "        self.xmaxList.append(xmax)\n",
    "        self.xminList.append(xmin)\n",
    "        self.ymaxList.append(ymax)\n",
    "        self.yminList.append(ymin)\n",
    "        self.confList.append(confidence)\n",
    "        self.classIDList.append(classID)\n",
    "\n",
    "    def makeDF(self):\n",
    "        data = {\n",
    "            self.frame : self.frameList,\n",
    "            self.xmax : self.xmaxList,\n",
    "            self.xmin : self.xminList,\n",
    "            self.ymax : self.ymaxList,\n",
    "            self.ymin : self.yminList,\n",
    "            self.conf: self.confList,\n",
    "            self.classID : self.classIDList\n",
    "        }\n",
    "        self.dataFrame = pd.DataFrame(data)\n",
    "    \n",
    "    def writeCSV(self, fileName):\n",
    "        self.makeDF()\n",
    "        file_name = fileName + '.csv'\n",
    "        self.dataFrame.to_csv(file_name, sep=',', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train/obj.names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\capstone_project\\Archipelago-Object-Tracking\\object_detector.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/capstone_project/Archipelago-Object-Tracking/object_detector.ipynb#ch0000001?line=31'>32</a>\u001b[0m writer \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoWriter(OUTPUT_FILE, fourcc, input_fps, frame_size, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/capstone_project/Archipelago-Object-Tracking/object_detector.ipynb#ch0000001?line=33'>34</a>\u001b[0m \u001b[39m# make Labels with labels_file\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/capstone_project/Archipelago-Object-Tracking/object_detector.ipynb#ch0000001?line=34'>35</a>\u001b[0m LABELS \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(LABELS_FILE)\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/capstone_project/Archipelago-Object-Tracking/object_detector.ipynb#ch0000001?line=36'>37</a>\u001b[0m \u001b[39m# set random color for labels and bounding boxes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/capstone_project/Archipelago-Object-Tracking/object_detector.ipynb#ch0000001?line=37'>38</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m4\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/obj.names'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils.video import FPS\n",
    "\n",
    "OUTPUT_NAME='output2'\n",
    "INPUT_FILE='../fish2_Trim.mp4'\n",
    "OUTPUT_FILE=OUTPUT_NAME+'.mp4'\n",
    "LABELS_FILE='train/obj.names'\n",
    "CONFIG_FILE='cfg/yolov4-obj2.cfg'\n",
    "WEIGHTS_FILE='yolov4-obj2_best.weights'\n",
    "CONFIDENCE_THRESHOLD=0.3\n",
    "\n",
    "H=None\n",
    "W=None\n",
    "\n",
    "d_output = DetectionOutput()\n",
    "\n",
    "# capture input video\n",
    "video_capture = cv2.VideoCapture(INPUT_FILE)\n",
    "\n",
    "# get input video's frame size\n",
    "frame_width = int(video_capture.get(3))\n",
    "frame_height = int(video_capture.get(4))\n",
    "frame_size = (frame_width,frame_height)\n",
    "\n",
    "# get input video's fps\n",
    "input_fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fps = FPS().start()\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"MJPG\") # for avi\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") # for mp4\n",
    "writer = cv2.VideoWriter(OUTPUT_FILE, fourcc, input_fps, frame_size, True)\n",
    "\n",
    "# make Labels with labels_file\n",
    "LABELS = open(LABELS_FILE).read().strip().split(\"\\n\")\n",
    "\n",
    "# set random color for labels and bounding boxes\n",
    "np.random.seed(4)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "\n",
    "# load the YOLO network model with config and weights file\n",
    "net = cv2.dnn.readNetFromDarknet(CONFIG_FILE, WEIGHTS_FILE)\n",
    "\n",
    "# determine only the *output* layer names that we need from YOLO\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "cnt =0\n",
    "\n",
    "# iterate through video frames\n",
    "while True:\n",
    "\tcnt+=1\n",
    "\tprint (\"Frame number\", cnt)\n",
    "\tok, image = video_capture.read()\n",
    "\tif not ok:\n",
    "\t\tbreak\n",
    "\t# transform image into a blob\n",
    "\tblob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\tnet.setInput(blob)\n",
    "\tif W is None or H is None:\n",
    "\t\t(H, W) = image.shape[:2]\n",
    "\tlayerOutputs = net.forward(ln)\n",
    "\n",
    "\t# initialize our lists of detected bounding boxes, confidences, and\n",
    "\t# class IDs, respectively\n",
    "\tboxes = []\n",
    "\tconfidences = []\n",
    "\tclassIDs = []\n",
    "\n",
    "\t# loop over each of the layer outputs\n",
    "\tfor output in layerOutputs:\n",
    "\t\t# loop over each of the detections\n",
    "\t\tfor detection in output:\n",
    "\t\t\t# extract the class ID and confidence (i.e., probability) of\n",
    "\t\t\t# the current object detection\n",
    "\t\t\tscores = detection[5:]\n",
    "\t\t\tclassID = np.argmax(scores)\n",
    "\t\t\tconfidence = scores[classID]\n",
    "\n",
    "\t\t\t# filter out weak predictions by ensuring the detected\n",
    "\t\t\t# probability is greater than the minimum probability\n",
    "\t\t\tif confidence > CONFIDENCE_THRESHOLD:\n",
    "\t\t\t\t# scale the bounding box coordinates back relative to the\n",
    "\t\t\t\t# size of the image, keeping in mind that YOLO actually\n",
    "\t\t\t\t# returns the center (x, y)-coordinates of the bounding\n",
    "\t\t\t\t# box followed by the boxes' width and height\n",
    "\t\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n",
    "\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t\t# use the center (x, y)-coordinates to derive the top and\n",
    "\t\t\t\t# and left corner of the bounding box\n",
    "\t\t\t\tx = int(centerX - (width / 2))\n",
    "\t\t\t\ty = int(centerY - (height / 2))\n",
    "\n",
    "\t\t\t\t# update our list of bounding box coordinates, confidences,\n",
    "\t\t\t\t# and class IDs\n",
    "\t\t\t\tboxes.append([x, y, int(width), int(height)])\n",
    "\t\t\t\tconfidences.append(float(confidence))\n",
    "\t\t\t\tclassIDs.append(classID)\n",
    "\n",
    "\t# apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "\t# boxes\n",
    "\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD,\n",
    "\t\tCONFIDENCE_THRESHOLD)\n",
    "\n",
    "\t# ensure at least one detection exists\n",
    "\tif len(idxs) > 0:\n",
    "\t\tprint(\"object detected\")\n",
    "\t\t# loop over the indexes we are keeping\n",
    "\t\tfor i in idxs.flatten():\n",
    "\t\t\t# extract the bounding box coordinates\n",
    "\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
    "\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "\t\t\tcolor = [int(c) for c in COLORS[classIDs[i]]]\n",
    "\n",
    "\t\t\tcv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\t\t\ttext = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "\t\t\tcv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t0.5, color, 2)\n",
    "\n",
    "\t\t\td_output.addData(cnt, x+w, x, y+h, y, format(confidences[i], \".4f\"), classIDs[i])\n",
    "\n",
    "\t# show the output image\n",
    "\tcv2.imshow(\"output\", image)\n",
    "\twriter.write(cv2.resize(image,frame_size))\n",
    "\tfps.update()\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t## if q is pressed terminate program\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\t## if space bar is pressed stop video\n",
    "\tif key == 32:\n",
    "\t\tkey2 = cv2.waitKey()\n",
    "\td_output.writeCSV(OUTPUT_NAME)\n",
    "\n",
    "fps.stop()\n",
    "\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# release the file pointers\n",
    "print(\"[INFO] cleaning up...\")\n",
    "writer.release()\n",
    "video_capture.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62def48e81a9cca8f364c24dfb725fce9c4e9f1dbd488585f19795e5af0a0958"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('object_tracking.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
